{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Introduction\n",
    "On this kernel, I will explain step by step I done in generating Script for Game of Thrones series.\n",
    "\n",
    "The site I used for scrapping is genius.com. This site contains a whole scripts of Game of Thrones series for all episodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "## Scrapping Episodes Urls\n",
    "### Loading the Required Packages\n",
    "Packages used for scrapping the episodes list are:\n",
    "* requests\n",
    "* BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # Used for doing the http request\n",
    "from bs4 import BeautifulSoup # Used for assisting the HTML read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Urls Scrapping\n",
    "Example URL for an album in genius.com is as following (https://genius.com/albums/Game-of-thrones/Season-1-scripts ). In our case, album means season of a series. Each album contains a full list of URLs used to access the lyrics of all the songs in the album. Then again, songs can be interpreted as episodes of a series in a single season (album).\n",
    "\n",
    "From the example above we can see that the season URLs are structured following this pattern below:\n",
    "> 'https://genius.com/albums/Game-of-thrones/Season-' + [Season Number] + '-scripts'\n",
    "\n",
    "We know that Game of Thrones has already finished with 8 seasons in total. Therefore we will have 8 different URLs for each season.\n",
    "\n",
    "In order to capture the URLs for each season, we can make a simple list comprehension to generate the URL for each season which follows the pattern we've discovered before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_urls = ['https://genius.com/albums/Game-of-thrones/Season-' + str(season_number) + '-scripts' for season_number in range(1,9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our season URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://genius.com/albums/Game-of-thrones/Season-1-scripts\n",
      "https://genius.com/albums/Game-of-thrones/Season-2-scripts\n",
      "https://genius.com/albums/Game-of-thrones/Season-3-scripts\n",
      "https://genius.com/albums/Game-of-thrones/Season-4-scripts\n",
      "https://genius.com/albums/Game-of-thrones/Season-5-scripts\n",
      "https://genius.com/albums/Game-of-thrones/Season-6-scripts\n",
      "https://genius.com/albums/Game-of-thrones/Season-7-scripts\n",
      "https://genius.com/albums/Game-of-thrones/Season-8-scripts\n"
     ]
    }
   ],
   "source": [
    "for season_url in season_urls:\n",
    "    print(season_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we already have the URLs for each season, we can take a look at the inner HTML from one of those URLs.\n",
    "We can do HTTP request using requests package that we imported, and then save the HTML result as a BeautifulSoup object.\n",
    "\n",
    "BeautifulSoup will wrap the result of a requests from raw string/text format to a structured data type known as BeautifulSoup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html class=\"snarly bagon_song_page--enabled song_stories_public_launch--enabled react_forums--disabled\" lang=\"en\" xml:lang=\"en\" xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:fb=\"http://www.facebook.com/2008/fbml\">\\n<head>\\n<base href=\"//genius.com/\" target=\"_top\"/>\\n<script type=\"text/javascript\">\\n//<![CDATA[\\n\\n  var _sf_startpt=(new Date()).getTime();\\n  if (window.performance && performance.mark) {\\n    window.performance.mark(\\'parse_start\\');\\n  }\\n\\n//]]>\\n</script>\\n<title>Game of Thrones - Season 1 Scripts Lyrics and Tracklist | Genius</title>\\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\\n<meta content=\"width=device-width,initial-scale=1\" name=\"viewport\"/>\\n<meta content=\"app-id=709482991\" name=\"apple-itunes-app\"/>\\n<link href=\"https://assets.genius.com/images/apple-touch-icon.png?1574199636\" rel=\"apple-touch-icon\"/>\\n<link href=\"https://assets.genius.com/images/apple-touch-icon.png?1574199636\" rel=\"apple-touch-icon\"/>\\n<!-- Mobile IE allows us to activate Cl'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get(season_urls[0])\n",
    "html_doc = r.text\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# only view snippet because the result is too large\n",
    "str(soup)[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the HTML text comprehensively, we can see that the URLs for each episode in a season are wrapped in an `a` tag with class name of `u-display_block`.\n",
    "\n",
    "In BeautifulSoup object, we can easily access each of html tag with specific attribute using a method called `.find_all()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"u-display_block\" href=\"https://genius.com/Game-of-thrones-winter-is-coming-annotated\">\n",
       "<h3 class=\"chart_row-content-title\">\n",
       "              Winter is Coming\n",
       "              <span class=\"chart_row-content-title-subtitle\">Lyrics</span>\n",
       "</h3>\n",
       "</a>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_containers = soup.find_all('a', class_='u-display_block')\n",
    "# take a look at one of the items\n",
    "url_containers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From one of the html `a` tag above we know that the URL for each episode is stored in the attribute `href`. Tag in `BeautifulSoup` is kind of similar to `dictionary` in python in term of (`attribute`, `value of attribute`) from a tag can be treated as (`key`, `value`) from a dictionary. Therefore we can get the URL of the episode by simply accessing the `href` attribute of an `a` tag using the same method as accessing value of a python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://genius.com/Game-of-thrones-winter-is-coming-annotated\n",
      "https://genius.com/Game-of-thrones-the-kingsroad-annotated\n",
      "https://genius.com/Game-of-thrones-lord-snow-annotated\n",
      "https://genius.com/Game-of-thrones-cripples-bastards-and-broken-things-annotated\n",
      "https://genius.com/Game-of-thrones-the-wolf-and-the-lion-annotated\n",
      "https://genius.com/Game-of-thrones-a-golden-crown-annotated\n",
      "https://genius.com/Game-of-thrones-you-win-or-you-die-annotated\n",
      "https://genius.com/Game-of-thrones-the-pointy-end-annotated\n",
      "https://genius.com/Game-of-thrones-baelor-annotated\n",
      "https://genius.com/Game-of-thrones-fire-and-blood-annotated\n"
     ]
    }
   ],
   "source": [
    "urls = [url_container['href'] for url_container in url_containers]\n",
    "\n",
    "# Take a look at the URLs inside\n",
    "for url in urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how to get the URL for each episode in a season of Game of Thrones. Next we need to do is extracting the URLs for all episodes from all seasons. We can do this by making simple loop of the season URLs and wrap all of what we have done before in order to get the episode URLs inside the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = []\n",
    "for season_url in season_urls:\n",
    "    \n",
    "    r = requests.get(season_url)\n",
    "    html_doc = r.text\n",
    "    soup = BeautifulSoup(html_doc)\n",
    "    \n",
    "    url_containers = soup.find_all('a', class_='u-display_block')\n",
    "    \n",
    "    for url_container in url_containers:\n",
    "        urls.append(url_container['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show number of episodes\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some anomalies in the URLs that we got. We know that Game of Thrones only consists of 73 episodes in total, but based on our scrap we captured more than 73 episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://genius.com/Game-of-thrones-winter-is-coming-annotated\n",
      "https://genius.com/Game-of-thrones-the-kingsroad-annotated\n",
      "https://genius.com/Game-of-thrones-lord-snow-annotated\n",
      "https://genius.com/Game-of-thrones-cripples-bastards-and-broken-things-annotated\n",
      "https://genius.com/Game-of-thrones-the-wolf-and-the-lion-annotated\n",
      "https://genius.com/Game-of-thrones-a-golden-crown-annotated\n",
      "https://genius.com/Game-of-thrones-you-win-or-you-die-annotated\n",
      "https://genius.com/Game-of-thrones-the-pointy-end-annotated\n",
      "https://genius.com/Game-of-thrones-baelor-annotated\n",
      "https://genius.com/Game-of-thrones-fire-and-blood-annotated\n",
      "https://genius.com/Game-of-thrones-the-north-remembers-annotated\n",
      "https://genius.com/Game-of-thrones-the-night-lands-annotated\n",
      "https://genius.com/Game-of-thrones-what-is-dead-may-never-die-annotated\n",
      "https://genius.com/Game-of-thrones-garden-of-bones-annotated\n",
      "https://genius.com/Game-of-thrones-the-ghost-of-harrenhal-annotated\n",
      "https://genius.com/Game-of-thrones-the-old-gods-and-the-new-annotated\n",
      "https://genius.com/Game-of-thrones-a-man-without-honor-annotated\n",
      "https://genius.com/Game-of-thrones-the-prince-of-winterfell-annotated\n",
      "https://genius.com/Game-of-thrones-blackwater-annotated\n",
      "https://genius.com/Game-of-thrones-valar-morghulis-annotated\n",
      "https://genius.com/Game-of-thrones-valar-dohaeris-annotated\n",
      "https://genius.com/Game-of-thrones-dark-wings-dark-words-annotated\n",
      "https://genius.com/Game-of-thrones-walk-of-punishment-annotated\n",
      "https://genius.com/Game-of-thrones-and-now-his-watch-is-ended-annotated\n",
      "https://genius.com/Game-of-thrones-kissed-by-fire-annotated\n",
      "https://genius.com/Game-of-thrones-the-climb-annotated\n",
      "https://genius.com/Game-of-thrones-the-bear-and-the-maiden-fair-annotated\n",
      "https://genius.com/Game-of-thrones-second-sons-annotated\n",
      "https://genius.com/Game-of-thrones-the-rains-of-castamere-annotated\n",
      "https://genius.com/Game-of-thrones-mhysa-annotated\n",
      "https://genius.com/Game-of-thrones-two-swords-annotated\n",
      "https://genius.com/Game-of-thrones-the-lion-and-the-rose-annotated\n",
      "https://genius.com/Game-of-thrones-breaker-of-chains-annotated\n",
      "https://genius.com/Game-of-thrones-oathkeeper-annotated\n",
      "https://genius.com/Game-of-thrones-first-of-his-name-annotated\n",
      "https://genius.com/Game-of-thrones-the-laws-of-gods-and-men-annotated\n",
      "https://genius.com/Game-of-thrones-mockingbird-annotated\n",
      "https://genius.com/Game-of-thrones-the-mountain-and-the-viper-annotated\n",
      "https://genius.com/Game-of-thrones-the-watchers-on-the-wall-annotated\n",
      "https://genius.com/Game-of-thrones-the-children-annotated\n",
      "https://genius.com/Game-of-thrones-season-4-preview-annotated\n",
      "https://genius.com/Game-of-thrones-the-wars-to-come-annotated\n",
      "https://genius.com/Game-of-thrones-the-house-of-black-and-white-annotated\n",
      "https://genius.com/Game-of-thrones-high-sparrow-annotated\n",
      "https://genius.com/Game-of-thrones-sons-of-the-harpy-annotated\n",
      "https://genius.com/Game-of-thrones-kill-the-boy-annotated\n",
      "https://genius.com/Game-of-thrones-unbowed-unbent-unbroken-annotated\n",
      "https://genius.com/Game-of-thrones-the-gift-annotated\n",
      "https://genius.com/Game-of-thrones-hardhome-annotated\n",
      "https://genius.com/Game-of-thrones-the-dance-of-dragons-annotated\n",
      "https://genius.com/Game-of-thrones-mothers-mercy-annotated\n",
      "https://genius.com/Game-of-thrones-season-5-trailer-breakdown-annotated\n",
      "https://genius.com/Game-of-thrones-the-red-woman-annotated\n",
      "https://genius.com/Game-of-thrones-home-annotated\n",
      "https://genius.com/Game-of-thrones-oathbreaker-annotated\n",
      "https://genius.com/Game-of-thrones-book-of-the-stranger-annotated\n",
      "https://genius.com/Game-of-thrones-the-door-annotated\n",
      "https://genius.com/Game-of-thrones-blood-of-my-blood-annotated\n",
      "https://genius.com/Game-of-thrones-the-broken-man-annotated\n",
      "https://genius.com/Game-of-thrones-no-one-annotated\n",
      "https://genius.com/Game-of-thrones-battle-of-the-bastards-annotated\n",
      "https://genius.com/Game-of-thrones-the-winds-of-winter-annotated\n",
      "https://genius.com/Game-of-thrones-dragonstone-annotated\n",
      "https://genius.com/Game-of-thrones-stormborn-annotated\n",
      "https://genius.com/Game-of-thrones-the-queens-justice-annotated\n",
      "https://genius.com/Game-of-thrones-the-spoils-of-war-annotated\n",
      "https://genius.com/Game-of-thrones-eastwatch-annotated\n",
      "https://genius.com/Game-of-thrones-beyond-the-wall-annotated\n",
      "https://genius.com/Game-of-thrones-the-dragon-and-the-wolf-annotated\n",
      "https://genius.com/Game-of-thrones-winterfell-annotated\n",
      "https://genius.com/Game-of-thrones-a-knight-of-the-seven-kingdoms-annotated\n",
      "https://genius.com/Game-of-thrones-the-long-night-annotated\n",
      "https://genius.com/Game-of-thrones-the-last-of-the-starks-annotated\n",
      "https://genius.com/Game-of-thrones-the-bells-annotated\n",
      "https://genius.com/Game-of-thrones-the-iron-throne-annotated\n"
     ]
    }
   ],
   "source": [
    "for url in urls:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking comprehensively at each item in our URL list, we could see there are preview and trailer episodes for both season 4 & 5 which are not needed. Therefore, we will remove those episodes from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = [url for url in urls if 'season' not in url]\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have clean and complete list of Game of Thrones' all episodes. Now we can move to scrap the script/conversations from each of those episodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Text Scrapping\n",
    "In this part we will start scrapping the content contained on each episode URLs that we've found. The data that we want to retrieve from each URL simply consists of:\n",
    "* Episode Number\n",
    "* Episode Title\n",
    "* Season Number\n",
    "* Release Date\n",
    "* Conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Finding\n",
    "What we gonna do in finding those data is starting with finding the html paths containing each one of the data. After the path found we will transform the data which naturally will be on raw html format to more readable datatypes and store them on predefined variables.\n",
    "\n",
    "Before we do web scrapping from all the episode URLs, It is better to do the process on one of the URL. Therefore we can find the processes and methods that we can apply to other URLs.\n",
    "\n",
    "So, we need to save one of our URL in one single variable for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://genius.com/Game-of-thrones-winter-is-coming-annotated'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = urls[0]\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to previous process, we need to get the HTML response from the URL and store them as `BeautifulSoup` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html class=\"snarly apple_music_player--enabled bagon_song_page--enabled song_stories_public_launch--enabled react_forums--disabled\" lang=\"en\" xml:lang=\"en\" xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:fb=\"http://www.facebook.com/2008/fbml\">\\n<head>\\n<base href=\"//genius.com/\" target=\"_top\"/>\\n<script type=\"text/javascript\">\\n//<![CDATA[\\n\\n  var _sf_startpt=(new Date()).getTime();\\n  if (window.performance && performance.mark) {\\n    window.performance.mark(\\'parse_start\\');\\n  }\\n\\n//]]>\\n</script>\\n<title>Game\\xa0of Thrones – Winter is Coming | Genius</title>\\n<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/>\\n<meta content=\"width=device-width,initial-scale=1\" name=\"viewport\"/>\\n<meta content=\"app-id=709482991\" name=\"apple-itunes-app\"/>\\n<link href=\"https://assets.genius.com/images/apple-touch-icon.png?1574199636\" rel=\"apple-touch-icon\"/>\\n<link href=\"https://assets.genius.com/images/apple-touch-icon.png?1574199636\" rel=\"apple-touch-icon\"/>\\n<!-- Mobile IE allows us to activate ClearType technology for smoothing fonts for easy reading -->\\n<meta content=\"on\" http-equiv=\"cleartype\"/>\\n<meta content=\"f63347d284f184b0\" name=\"y_key\"/>\\n<meta content=\"Genius\" property=\"og:site_name\"/>\\n<meta content=\"265539304824\" property=\"fb:app_id\"/>\\n<meta content=\"308252472676410\" property=\"fb:pages\"/>\\n<link href=\"https://genius.com/opensearch.xml\" rel=\"search\" title=\"Genius\" type=\"application/opensearchdescription+xml\"/>\\n<script>\\n!function(){if(\\'PerformanceLongTaskTiming\\' in window){var g=window.__tti={e:[]};\\ng.o=new PerformanceObserver(function(l){g.e=g.e.concat(l.getEntries())});\\ng.o.observe({entryTypes:[\\'longtask\\']})}}();\\n</script>\\n<script>\\n  var CURRENT_USER = null;\\n  var CANONICAL_DOMAIN = \"genius.com\";\\n  var CANONICAL_DOMAIN_PARTS_LENGTH = 2;\\n  var CURRENT_TAG = {\"tag\":{\"always_allow_personal_annotation\":false,\"beefy\":true,\"created_at\":\"2014-05-22T00:34:21Z\",\"deleted_at\":null,\"description\":\"Non-Music is the home of everything non-music on Genius from literature, to fil'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get(url)\n",
    "html_doc = r.text\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# take a look inside\n",
    "# again only snippet because the result too large\n",
    "str(soup)[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Episode Number & Title\n",
    "Based on the HTML text that we loaded above, the episode number and title are wrapped in a `div` tag with class name of `track_listing-track track_listing-track--current`.\n",
    "Once again we can easily access this tag using `.find_all()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"track_listing-track track_listing-track--current\">\n",
       " <span class=\"track_listing-track_number\">1.  </span>\n",
       " <span>\n",
       "             Winter is Coming\n",
       "             \n",
       "             \n",
       "           </span>\n",
       " </div>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode = soup.find_all('div', class_='track_listing-track track_listing-track--current')\n",
    "# take a look inside\n",
    "episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the result is a list containing a single element of inner HTML from a span. However, the inner HTML itself is still in HTML format. We can get all the texts inside HTML using `.text` attribute of a soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1.\\xa0\\xa0\\n\\n            Winter is Coming\\n            \\n            \\n          \\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode = episode[0].text\n",
    "# take a look inside\n",
    "episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further text processing is needed to get the `number` and `title` of an episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\n",
      "Winter is Coming\n"
     ]
    }
   ],
   "source": [
    "# creating a list by splitting the string using '\\n'\n",
    "episode = episode.split('\\n')\n",
    "\n",
    "# remove unused and empty strings\n",
    "episode = ''.join(e + ' ' for e in episode)\n",
    "episode = episode.split(' ')\n",
    "episode = list(filter(None, episode))\n",
    "\n",
    "# assign episode number and episode title to different variables\n",
    "episode_number = ''.join('Episode ' + episode[0].split('.')[0])\n",
    "episode_title = ''.join(e + ' ' for e in episode[1:])[:-1]\n",
    "\n",
    "# show the results\n",
    "print(episode_number)\n",
    "print(episode_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Season Number\n",
    "Season number is wrapped in an `a` tag with class name of `song_album-info-title`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Season 1\n"
     ]
    }
   ],
   "source": [
    "# get all elements inside 'a' tag, remove enters, convert to list splitted by empty space\n",
    "season = soup.find_all('a', class_='song_album-info-title')[0].text.replace('\\n','').split(' ')\n",
    "\n",
    "# remove empty strings and concat all the remaining\n",
    "season = list(filter(None, season))\n",
    "season = ''.join(s + ' ' for s in season[:-1])[:-1]\n",
    "\n",
    "print(season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Release Date\n",
    "Release date is wrapped in an `span` tag with class name of `metadata_unit-info metadata_unit-info--text_only`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April 17, 2011\n"
     ]
    }
   ],
   "source": [
    "# get all elements inside 'a' tag\n",
    "release_date = soup.find_all('span', class_='metadata_unit-info metadata_unit-info--text_only')\n",
    "release_date = release_date[0].text\n",
    "\n",
    "print(release_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the date stored in a more simplified format. We can use method `.strptime()` and `.strftime()` from `datetime`. To do this we need to import `datetime` from package `datetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-04-17\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "release_date = datetime.strptime(release_date, '%B %d, %Y')\n",
    "release_date = datetime.strftime(release_date, '%Y-%m-%d')\n",
    "\n",
    "print(release_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversations\n",
    "Scrapping the conversations part will have complex and long processes. These processes include getting the raw html text, removing unused tags, filtering the tags needed, and so many text cleansing processes.\n",
    "\n",
    "As a start, we kno that the conversation part is stored in a `div` tag with class name of `lyrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div class=\"lyrics\">\\n<!--sse-->\\n<p><b>EPISODE 1 - WINTER IS COMING</b></p>\\n<hr/><p>[First scene opens with three Rangers riding through a tunnel, leaving the Wall, and going into the woods. (Eerie music in background) One Ranger splits off and finds a campsite full of mutilated bodies, including a child hanging from a tree branch. <a annotation-fragment=\"1639510\" class=\"referent\" classification=\"accepted\" data-id=\"1639510\" href=\"/Game-of-thrones-winter-is-coming-annotated#note-1639510\" image=\"false\" ng-class=\"{\\n          \\'referent--linked_to_preview\\': song_ctrl.referent_has_preview(fragment_id),\\n          \\'referent--linked_to_preview_active\\': song_ctrl.highlight_preview_referent(fragment_element_id),\\n          \\'referent--purple_indicator\\': song_ctrl.show_preview_referent_indicator(fragment_element_id)\\n        }\" ng-click=\"open()\" on-hover-with-no-digest=\"set_current_hover_and_digest(hover ? fragment_id : undefined)\" pending-editorial-actions-count=\"1\" prevent-default-click=\"\">A birds-eye view shows the bodies arranged in a shield-like pattern.</a> The Ranger rides back to the other two.]<br/>\\n<br/>\\n<a annotation-fragment=\"3326661\" class=\"referent\" classification=\"accepted\" data-id=\"3326661\" href=\"/Game-of-thrones-winter-is-coming-annotated#note-3326661\" image=\"false\" ng-class=\"{\\n          \\'referent--linked_to_preview\\': song_ctrl.referent_has_preview(fragment_id),\\n          \\'referent--linked_to_preview_active\\': song_ctrl.highlight_preview_referent(fragment_element_id),\\n          \\'referent--purple_indicator\\': song_ctrl.show_preview_referent_indicator(fragment_element_id)\\n        }\" ng-click=\"open()\" on-hover-with-no-digest=\"set_current_hover_and_digest(hover ? fragment_id : undefined)\" pending-editorial-actions-count=\"0\" prevent-default-click=\"\">WAYMAR ROYCE: What d’you expect? They’re savages. One lot steals a goat from another lot and before you know it, they’re ripping each other to pieces.</a><br/>\\n<br/>\\nWILL: <a annotation-fragment=\"3354672\" class=\"referent\" clas'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics = soup.find_all(\"div\", class_=\"lyrics\")[0]\n",
    "\n",
    "# again only snippet because the result too large\n",
    "str(lyrics)[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there are a lot of tags on our soup. We can easily remove those unused tags using method `.extract()` of a soup. In order to do that we need to convert our soup to a BeautifulSoup object, and then apply the `.extract()` method for each unused tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><body><div class=\"lyrics\">\n",
      "<!--sse-->\n",
      "<p><b>EPISODE 1 - WINTER IS COMING</b></p>\n",
      "<p>[First scene opens with three Rangers riding through a tunnel, leaving the Wall, and going into the woods. (Eerie music in background) One Ranger splits off and finds a campsite full of mutilated bodies, including a child hanging from a tree branch. <a annotation-fragment=\"1639510\" class=\"referent\" classification=\"accepted\" data-id=\"1639510\" href=\"/Game-of-thrones-winter-is-coming-annotated#note-1639510\" image=\"false\" ng-class=\"{\n",
      "          'referent--linked_to_preview': song_ctrl.referent_has_preview(fragment_id),\n",
      "          'referent--linked_to_preview_active': song_ctrl.highlight_preview_referent(fragment_element_id),\n",
      "          'referent--purple_indicator': song_ctrl.show_preview_referent_indicator(fragment_element_id)\n",
      "        }\" ng-click=\"open()\" on-hover-with-no-digest=\"set_current_hover_and_digest(hover ? fragment_id : undefined)\" pending-editorial-actions-count=\"1\" prevent-default-click=\"\">A birds-eye view shows the bodies arranged in a shield-like pattern.</a> The Ranger rides back to the other two.]\n",
      "\n",
      "<a annotation-fragment=\"3326661\" class=\"referent\" classification=\"accepted\" data-id=\"3326661\" href=\"/Game-of-thrones-winter-is-coming-annotated#note-3326661\" image=\"false\" ng-class=\"{\n",
      "          'referent--linked_to_preview': song_ctrl.referent_has_preview(fragment_id),\n",
      "          'referent--linked_to_preview_active': song_ctrl.highlight_preview_referent(fragment_element_id),\n",
      "          'referent--purple_indicator': song_ctrl.show_preview_referent_indicator(fragment_element_id)\n",
      "        }\" ng-click=\"open()\" on-hover-with-no-digest=\"set_current_hover_and_digest(hover ? fragment_id : undefined)\" pending-editorial-actions-count=\"0\" prevent-default-click=\"\">WAYMAR ROYCE: What d’you expect? They’re savages. One lot steals a goat from another lot and before you know it, they’re ripping each other to pieces.</a>\n",
      "\n",
      "WILL: <a annotation-fragment=\"3354672\" class=\"referent\" classification=\"accepted\" data-id=\"3354672\" href=\"/Game-of-thrones-winter-is-coming-annotated#note-3354672\" image=\"false\" ng-class=\"{\n",
      "          'referent--linked_to_preview': song_ctrl.referent_has_preview(fragment_id),\n",
      "          'referent--linked_to_preview_active': song_ctrl.highlight_preview_referent(fragment_element_id),\n",
      "          'referent--purple_indicator': song_ctrl.show_preview_referent_indicator(fragment_element_id)\n",
      "        }\" ng-click=\"open()\" on-hover-with-no-digest=\"set_current_hover_and_digest(hover ? fragment_id : undefined)\" pending-editorial-actions-count=\"0\" prevent-default-click=\"\">I’ve never seen wildlings do a thing like this. I’ve never seen a thing like this, not ever in my life.</a>\n",
      "\n",
      "WAYMAR ROYCE: How close did you get?\n",
      "\n",
      "WILL: Close as any man would.\n",
      "\n",
      "GARED: We should head back to the wall.\n",
      "\n",
      "<a annotation-fragment=\"3420725\" class=\"referent\" classification=\"accepted\" data-id=\"3420725\" href=\"/Game-of-thrones-winter-is-coming-annotated#note-3420725\" image=\"false\" ng-class=\"{\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "lyrics = BeautifulSoup(str(lyrics))\n",
    "[s.extract() for s in lyrics('br')]\n",
    "[s.extract() for s in lyrics('i')]\n",
    "[s.extract() for s in lyrics('hr')]\n",
    "[s.extract() for s in lyrics('h1')]\n",
    "[s.extract() for s in lyrics('h2')]\n",
    "[s.extract() for s in lyrics('h3')]\n",
    "\n",
    "# take a look inside\n",
    "# again only snippet because the result too large\n",
    "print(str(lyrics)[:3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we already removed some of unused tags in our `lyrics`. From this we can see that all of the conversations are wrapped in `p` tag and they are clearly written by matching with this pattern `[Person]:[Sentences]`.\n",
    "\n",
    "However, other text that is not considered as conversation also stored on this tag. So, we need to clean the data again later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('EPISODE 1 - WINTER IS COMING',)\n",
      "('[First scene opens with three Rangers riding through a tunnel, leaving the Wall, and going into the woods. (Eerie music in background) One Ranger splits off and finds a campsite full of mutilated bodies, including a child hanging from a tree branch. A birds-eye view shows the bodies arranged in a shield-like pattern. The Ranger rides back to the other two.]',)\n",
      "('WAYMAR ROYCE', ' What d’you expect? They’re savages. One lot steals a goat from another lot and before you know it, they’re ripping each other to pieces.')\n",
      "('WILL', ' I’ve never seen wildlings do a thing like this. I’ve never seen a thing like this, not ever in my life.')\n",
      "('WAYMAR ROYCE', ' How close did you get?')\n",
      "('WILL', ' Close as any man would.')\n",
      "('GARED', ' We should head back to the wall.')\n",
      "('ROYCE', ' Do the dead frighten you?')\n",
      "('GARED', ' Our orders were to track the wildlings. We tracked them. They won’t trouble us no more.')\n",
      "('ROYCE', ' You don’t think he’ll ask us how they died? Get back on your horse.')\n"
     ]
    }
   ],
   "source": [
    "# get the 'p' tags inner HTML\n",
    "paragraphs = lyrics.find_all('p')\n",
    "\n",
    "# create variable to store the conversations\n",
    "conversations = []\n",
    "\n",
    "# iterating all 'p' tags found\n",
    "for p in paragraphs:\n",
    "    # get the inner text of p, create list by splitting text using '\\n', and extend them to list outside the loop\n",
    "    conversations.extend(p.text.split('\\n'))\n",
    "    \n",
    "# remove empty strings\n",
    "conversations = list(filter(None, conversations))\n",
    "\n",
    "# by following the [person]:[sentences] pattern, convert the string inside list to tuple format\n",
    "conversations = [tuple(s.split(':')) for s in conversations]\n",
    "\n",
    "for conversation in conversations[:10]:\n",
    "    print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all the conversations stored in a list containing tuple of (`person`,`sentence`) format. Unfortunately, some of the entries of our list don't match with the format. This indicates that those values are not considered as a conversation. Therefore we need to remove them.\n",
    "\n",
    "Now we have two different types of tuple on our list which are tuple consisting 2 values, and tuple consisting only one value. Let's take a look on those two types of tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | 2 values | ILLYRIO: Soon. The Dothraki never stay still for long.\n",
      "1 | 2 values | VISERYS: Is it true they lie with their horses?\n",
      "2 | 2 values | ILLYRIO: I wouldn’t ask Khal Drogo.\n",
      "3 | 2 values | VISERYS: Do you take me for a fool?\n",
      "4 | 2 values | ILLYRIO: I take you for a king. Kings lack the caution of common men. My apologies if I’ve given offense.\n",
      "5 | 2 values | VISERYS: I know how to play a man like Drogo. I give him a queen and he gives me an army.\n",
      "6 | 1 value | DAENERYS (pleadingly) I don’t want to be his queen. I want to go home.\n",
      "7 | 2 values | VISERYS: So do I. I want us both to go home. But they took it from us. So tell me, sweet sister, how do we go home?\n",
      "8 | 2 values | DAENERYS: I don’t know.\n",
      "9 | 2 values | VISERYS: We go home with an army. With Khal Drogo’s army. I would let his whole tribe fuck you, all 40,000 men and their horses too, if that’s what it took.\n"
     ]
    }
   ],
   "source": [
    "for index, conversation in enumerate(conversations[255:265]):\n",
    "    if len(conversation) >= 2:\n",
    "        print(str(index) + ' | 2 values | ' + ''.join(str(c) + ':' for c in conversation)[:-1])\n",
    "    else:\n",
    "        print(str(index) + ' | 1 value | ' + ''.join(str(c) + ':' for c in conversation)[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we can just remove the tuple that only consisting 1 value and store the rest of tuples as our clean data. However, It turns out that some of the conversations actually are not following the `[person]:[sentences]` format. We need to do some `regex` matching in order not to lose those conversations.\n",
    "\n",
    "But before doing that, we need to remove tuples that represent background situation. Those tuples have elements written inside a bracket `[]`. We can remove those tuples using some `regex` matching. For a better understanding about `regex`, you can do exercise here: https://regexr.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GARED', ' It’s …'),\n",
       " ('[As he speaks, a CREATURE with glowing blue eyes rises behind ROYCE. ROYCE turns, the CREATURE strikes. The scene shifts to WILL, who hears a man crying out. The three horses stampede past him. He turns and sees someone standing very still in the distance. The figure turns – it’s the child who had been suspended in the tree, now with glowing blue eyes. WILL turns and runs.',),\n",
       " ('GARED is also fleeing, and we hear strange growls and catch glimpses of the CREATURE. Both terrified RANGERS stop, some distance apart, to catch their breath. WILL sees a CREATURE behead GARED. WILL sinks to his knees and the CREATURE tosses GARED’S head to him.]',),\n",
       " ('JON', ' Go on. Father’s watching.'),\n",
       " ('JON', ' And your mother.'),\n",
       " ('SEPTA MORDANE (to SANSA)', ' Fine work, as always. Well done.'),\n",
       " ('SANSA', ' Thank you.'),\n",
       " ('SEPTA MORDANE',\n",
       "  ' I love the detail that you’ve managed to get in this corners. … Quite beautiful … the stitching …'),\n",
       " ('NED',\n",
       "  ' And which one of you was a marksman at ten? Keep practicing, Bran. Go on.'),\n",
       " ('JON', ' Don’t think too much, Bran.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# regex to find conversations in [ some text ] format\n",
    "regex = '(.+)\\[.+\\](.+)|(.+)\\[.+\\]|\\[.+\\]'\n",
    "pattern = re.compile(regex)\n",
    "\n",
    "for index, conversation in enumerate(conversations):\n",
    "    if len(conversation) <= 1:\n",
    "        match = pattern.findall(conversation[0])\n",
    "        if len(match) > 0:\n",
    "            conversations[index] = tuple((''.join(e + ' ' for e in list(filter(None, match[0]))).replace('    ',' ').replace('   ',' ').replace('  ', ' ')).split('\\n'))\n",
    "\n",
    "conversations = list(filter(None, conversations))\n",
    "conversations = [c for c in conversations if len(c[0]) > 0]\n",
    "\n",
    "# show\n",
    "conversations[15:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventhough we already filtered some of the background situations, there are some cases in which the background situation is divided to two different lines which are not captured by our regex before. We need to clean the list again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GARED', ' It’s …'),\n",
       " ('JON', ' Go on. Father’s watching.'),\n",
       " ('JON', ' And your mother.'),\n",
       " ('SEPTA MORDANE (to SANSA)', ' Fine work, as always. Well done.'),\n",
       " ('SANSA', ' Thank you.'),\n",
       " ('SEPTA MORDANE',\n",
       "  ' I love the detail that you’ve managed to get in this corners. … Quite beautiful … the stitching …'),\n",
       " ('NED',\n",
       "  ' And which one of you was a marksman at ten? Keep practicing, Bran. Go on.'),\n",
       " ('JON', ' Don’t think too much, Bran.'),\n",
       " ('ROBB', ' Relax your bow arm.'),\n",
       " ('JON/ROBB', ' Quick, Bran, faster!')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex that match for '[ some text' and 'some text ]' format\n",
    "regex = '^\\[.+|.+\\]$'\n",
    "pattern = re.compile(regex)\n",
    "\n",
    "for index, conversation in enumerate(conversations):\n",
    "    if len(conversation) <= 1:\n",
    "        match = pattern.search(conversation[0])\n",
    "        if match:\n",
    "            conversations[index] = None\n",
    "\n",
    "conversations = list(filter(None, conversations))\n",
    "conversations[15:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have filtered all of the background situations, our list now should contains conversations only. However, we still have not do anything about the conversations that is not following the `[person]:[sentence]` format.\n",
    "\n",
    "Let's take a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | EPISODE 1 - WINTER IS COMING\n",
      "36 | NED nods yes, and WILL is positioned on the tree limb that serves as a block. \n",
      "129 | ROBERT (to BRAN) Ooh. Show us your muscles. You’ll be a soldier.\n",
      "170 | Scene changes to the Winterfell crypt, at Lyanna’s tomb. \n",
      "187 | VISERYS (to DAENERYS) Do you see how long his hair is? When Dothraki are defeated in combat, they cut off their braid so the whole world can see their shame. Khal Drogo has never been defeated. He’s a savage, of course, but he’s one of the finest killers alive. And you will be his queen.\n",
      "201 | DAENERYS (pleadingly) I don’t want to be his queen. I want to go home.\n",
      "249 | CATELYN (in desperation) Is this your first time in the North, Your Grace?\n",
      "330 | .\n",
      "333 | / BLACKOUT /\n"
     ]
    }
   ],
   "source": [
    "for index, conversation in enumerate(conversations):\n",
    "    if len(conversation) < 2:\n",
    "        print(str(index) + ' | ' + conversation[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look closely, these conversations match the pattern `[person in uppercase] (some text) [sentences]`. Besides, there can also be some conversations that do not have the `(some text)` part.\n",
    "\n",
    "Once again, we will extract the `person` and `sentence` from those conversations using `regex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ARYA', ' Where’s the Imp?'),\n",
       " ('SANSA', ' Will you shut up?'),\n",
       " ('ROBERT',\n",
       "  ' Who have we here? You must be Robb. (To Sansa) My, you’re a pretty one. (To Arya) Your name is?'),\n",
       " ('ARYA', ' Arya.'),\n",
       " ('ROBERT', ' (to BRAN) Ooh. Show us your muscles. You’ll be a soldier.'),\n",
       " ('ARYA', ' That’s Jaime Lannister. The queen’s twin brother.'),\n",
       " ('SANSA', ' Would you please shut up.'),\n",
       " ('NED', ' My queen.'),\n",
       " ('CATELYN', ' My queen.'),\n",
       " ('ROBERT', ' Take me to your crypt. I want to pay my respects.')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex to match with '[person in uppercase] [rest of the text]' and '[person in uppercase] (some text) [rest of the text]' format\n",
    "regex = '^([A-Z]{2,})(.+)'\n",
    "pattern = re.compile(regex)\n",
    "\n",
    "for index, conversation in enumerate(conversations):\n",
    "    if len(conversation) <= 1:\n",
    "        match = pattern.findall(conversation[0])\n",
    "        if len(match) > 0:\n",
    "            conversations[index] = (match[0][0], match[0][-1])\n",
    "    \n",
    "# take a look\n",
    "conversations[125:135]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have all the conversations on desired format. Now our list of `conversations` should only have conversation on two valued tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Scene changes to the Winterfell crypt, at Lyanna’s tomb. ',)\n",
      "('.',)\n",
      "('/ BLACKOUT /',)\n"
     ]
    }
   ],
   "source": [
    "for conversation in conversations:\n",
    "    if len(conversation) < 2:\n",
    "        print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now take out all of the one valued tuples from our list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EPISODE', ' 1 - WINTER IS COMING'),\n",
       " ('WAYMAR ROYCE',\n",
       "  ' What d’you expect? They’re savages. One lot steals a goat from another lot and before you know it, they’re ripping each other to pieces.'),\n",
       " ('WILL',\n",
       "  ' I’ve never seen wildlings do a thing like this. I’ve never seen a thing like this, not ever in my life.'),\n",
       " ('WAYMAR ROYCE', ' How close did you get?'),\n",
       " ('WILL', ' Close as any man would.'),\n",
       " ('GARED', ' We should head back to the wall.'),\n",
       " ('ROYCE', ' Do the dead frighten you?'),\n",
       " ('GARED',\n",
       "  ' Our orders were to track the wildlings. We tracked them. They won’t trouble us no more.'),\n",
       " ('ROYCE',\n",
       "  ' You don’t think he’ll ask us how they died? Get back on your horse.'),\n",
       " ('WILL',\n",
       "  ' Whatever did it to them could do it to us. They even killed the children.')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations = [conversation for conversation in conversations if len(conversation) > 1]\n",
    "\n",
    "# take a look\n",
    "conversations[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have our desired list of conversations which is the last piece of data that we want to scrap. From now on we will combine all of the data that we already gathered which are `episode number`, `episode title`, `season number`, `release date`, and `conversation`. We will put all these data together and store them in a `dataframe`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataframe\n",
    "For creating dataframe we need to import the required package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a better and tidier dataframe, we can not put raw tuples as our entry. Therefore we need to separate our conversations data as two different set of values which are `person` and `sentence`. We are going to create pandas `Series` for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = pd.Series([c[0] for c in conversations])\n",
    "sentence = pd.Series([c[1] for c in conversations])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a quick look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         EPISODE\n",
      "1    WAYMAR ROYCE\n",
      "2            WILL\n",
      "3    WAYMAR ROYCE\n",
      "4            WILL\n",
      "dtype: object\n",
      "0                                 1 - WINTER IS COMING\n",
      "1     What d’you expect? They’re savages. One lot s...\n",
      "2     I’ve never seen wildlings do a thing like thi...\n",
      "3                               How close did you get?\n",
      "4                              Close as any man would.\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(person.head())\n",
    "print(sentence.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the separated data in different variables. We can now wrap all of these variables to a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 331 entries, 0 to 330\n",
      "Data columns (total 6 columns):\n",
      "Release Date     331 non-null object\n",
      "Season           331 non-null object\n",
      "Episode          331 non-null object\n",
      "Episode Title    331 non-null object\n",
      "Name             331 non-null object\n",
      "Sentence         331 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 15.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>EPISODE</td>\n",
       "      <td>1 - WINTER IS COMING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>WAYMAR ROYCE</td>\n",
       "      <td>What d’you expect? They’re savages. One lot s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>WILL</td>\n",
       "      <td>I’ve never seen wildlings do a thing like thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>WAYMAR ROYCE</td>\n",
       "      <td>How close did you get?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>WILL</td>\n",
       "      <td>Close as any man would.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Release Date    Season    Episode     Episode Title          Name  \\\n",
       "0   2011-04-17  Season 1  Episode 1  Winter is Coming       EPISODE   \n",
       "1   2011-04-17  Season 1  Episode 1  Winter is Coming  WAYMAR ROYCE   \n",
       "2   2011-04-17  Season 1  Episode 1  Winter is Coming          WILL   \n",
       "3   2011-04-17  Season 1  Episode 1  Winter is Coming  WAYMAR ROYCE   \n",
       "4   2011-04-17  Season 1  Episode 1  Winter is Coming          WILL   \n",
       "\n",
       "                                            Sentence  \n",
       "0                               1 - WINTER IS COMING  \n",
       "1   What d’you expect? They’re savages. One lot s...  \n",
       "2   I’ve never seen wildlings do a thing like thi...  \n",
       "3                             How close did you get?  \n",
       "4                            Close as any man would.  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script = pd.DataFrame({\n",
    "    'Season': season,\n",
    "    'Episode': episode_number,\n",
    "    'Episode Title': episode_title,\n",
    "    'Sentence': sentence,\n",
    "    'Name': person,\n",
    "    'Release Date': release_date\n",
    "})\n",
    "script = script[['Release Date','Season','Episode','Episode Title','Name','Sentence']]\n",
    "print(script.info())\n",
    "script.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can still see there are some data that considered dirty in this dataframe. On the top position we have data with Name `EPISODE` and Sentence `1 - WINTER IS COMING`. Other case is different representation of same person, such as `DAENERYS` and `DAENERYS TARGARYEN`. There are still some other cases as well. However, we will clean this later on `Post Scrapping Data Cleansing` part. For now we already have at least all of the conversation with no loss and in our desired format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap The Process in Functions\n",
    "Based on what we have done before, we already know how to scrap and gather all the data required to make a dataframe of conversations from one episode of Game of Thrones. We can now iterate all of the episode `URLs` and do the whole process to each of them to get all of the scripts.\n",
    "\n",
    "However, instead of putting the whole process inside a single loop, it is better to wrap each of the independent process in different functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_episode(soup):\n",
    "    episode = soup.find_all('div', class_='track_listing-track track_listing-track--current')[0].text.split('\\n')\n",
    "    episode = ''.join(e + ' ' for e in episode)\n",
    "    episode = episode.split(' ')\n",
    "    episode = list(filter(None, episode))\n",
    "\n",
    "    episode_number = ''.join('Episode ' + episode[0].split('.')[0])\n",
    "    episode_title = ''.join(e + ' ' for e in episode[1:])[:-1]\n",
    "    \n",
    "    return episode_number, episode_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(soup):\n",
    "    season = soup.find_all('a', class_='song_album-info-title')[0].text.replace('\\n','').split(' ')\n",
    "    season = list(filter(None, season))\n",
    "    season = ''.join(s + ' ' for s in season[:-1])[:-1]\n",
    "    \n",
    "    return season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Release Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_release_date(soup):\n",
    "    release_date = soup.find_all('span', class_='metadata_unit-info metadata_unit-info--text_only')[0].text\n",
    "    release_date = datetime.strptime(release_date, '%B %d, %Y')\n",
    "    release_date = datetime.strftime(release_date, '%Y-%m-%d')\n",
    "    \n",
    "    return release_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_conversations(soup):\n",
    "    lyrics = soup.find_all(\"div\", class_=\"lyrics\")[0]\n",
    "\n",
    "    lyrics = BeautifulSoup(str(lyrics))\n",
    "    [s.extract() for s in lyrics('br')]\n",
    "    [s.extract() for s in lyrics('i')]\n",
    "    [s.extract() for s in lyrics('hr')]\n",
    "    [s.extract() for s in lyrics('h1')]\n",
    "    [s.extract() for s in lyrics('h2')]\n",
    "    [s.extract() for s in lyrics('h3')]\n",
    "\n",
    "    paragraphs = lyrics.find_all('p')\n",
    "\n",
    "    conversations = []\n",
    "\n",
    "    for p in paragraphs:\n",
    "        conversations.extend(p.text.split('\\n'))\n",
    "\n",
    "    conversations = list(filter(None, conversations))\n",
    "    conversations = [tuple(s.split(':')) for s in conversations]\n",
    "    \n",
    "    regex = '(.+)\\[.+\\](.+)|(.+)\\[.+\\]|\\[.+\\]'\n",
    "    pattern = re.compile(regex)\n",
    "    \n",
    "    for index, conversation in enumerate(conversations):\n",
    "        if len(conversation) <= 1:\n",
    "            match = pattern.findall(conversation[0])\n",
    "            if len(match) > 0:\n",
    "                conversations[index] = tuple((''.join(e + ' ' for e in list(filter(None, match[0]))).replace('    ',' ').replace('   ',' ').replace('  ', ' ')).split('\\n'))\n",
    "                \n",
    "    conversations = list(filter(None, conversations))\n",
    "    conversations = [c for c in conversations if len(c[0]) > 0]\n",
    "    \n",
    "    regex = '^\\[.+|.+\\]$'\n",
    "    pattern = re.compile(regex)\n",
    "    \n",
    "    for index, conversation in enumerate(conversations):\n",
    "        if len(conversation) <= 1:\n",
    "            match = pattern.search(conversation[0])\n",
    "            if match:\n",
    "                conversations[index] = None\n",
    "                \n",
    "    conversations = list(filter(None, conversations))\n",
    "    \n",
    "    regex = '^([A-Z]{2,})(.+)'\n",
    "    pattern = re.compile(regex)\n",
    "    \n",
    "    for index, conversation in enumerate(conversations):\n",
    "        if len(conversation) <= 1:\n",
    "            match = pattern.findall(conversation[0])\n",
    "            if len(match) > 0:\n",
    "                conversations[index] = (match[0][0], match[0][-1])\n",
    "                \n",
    "    conversations = [conversation for conversation in conversations if len(conversation) > 1]\n",
    "    \n",
    "    return conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(**kwargs):\n",
    "    \n",
    "    person = pd.Series([c[0] for c in conversations])\n",
    "    sentence = pd.Series([c[1] for c in conversations])\n",
    "    \n",
    "    script = pd.DataFrame({\n",
    "        'Season': season,\n",
    "        'Episode': episode_number,\n",
    "        'Episode Title': episode_title,\n",
    "        'Sentence': sentence,\n",
    "        'Name': person,\n",
    "        'Release Date': release_date\n",
    "    })\n",
    "    \n",
    "    script = script[['Release Date','Season','Episode','Episode Title','Name','Sentence']]\n",
    "    \n",
    "    return script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate All Episodes\n",
    "After wrapping all of our independent processes in different functions, next thing we should do is applying these functions to all of our episode `URLs` to get the whole script of Game of Thrones. To do this we will make a simple for loop to iterate all of our `URLs`, and put the functions we have made before inside the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script from: https://genius.com/Game-of-thrones-winter-is-coming-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-kingsroad-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-lord-snow-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-cripples-bastards-and-broken-things-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-wolf-and-the-lion-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-a-golden-crown-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-you-win-or-you-die-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-pointy-end-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-baelor-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-fire-and-blood-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-north-remembers-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-night-lands-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-what-is-dead-may-never-die-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-garden-of-bones-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-ghost-of-harrenhal-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-old-gods-and-the-new-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-a-man-without-honor-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-prince-of-winterfell-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-blackwater-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-valar-morghulis-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-valar-dohaeris-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-dark-wings-dark-words-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-walk-of-punishment-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-and-now-his-watch-is-ended-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-kissed-by-fire-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-climb-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-bear-and-the-maiden-fair-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-second-sons-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-rains-of-castamere-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-mhysa-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-two-swords-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-lion-and-the-rose-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-breaker-of-chains-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-oathkeeper-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-first-of-his-name-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-laws-of-gods-and-men-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-mockingbird-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-mountain-and-the-viper-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-watchers-on-the-wall-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-children-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-wars-to-come-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-house-of-black-and-white-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-high-sparrow-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-sons-of-the-harpy-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-kill-the-boy-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-unbowed-unbent-unbroken-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-gift-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-hardhome-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-dance-of-dragons-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-mothers-mercy-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-red-woman-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-home-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-oathbreaker-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-book-of-the-stranger-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-door-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-blood-of-my-blood-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-broken-man-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-no-one-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-battle-of-the-bastards-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-winds-of-winter-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-dragonstone-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-stormborn-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-queens-justice-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-spoils-of-war-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-eastwatch-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-beyond-the-wall-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-dragon-and-the-wolf-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-winterfell-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-a-knight-of-the-seven-kingdoms-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-long-night-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-last-of-the-starks-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-bells-annotated added\n",
      "Script from: https://genius.com/Game-of-thrones-the-iron-throne-annotated added\n"
     ]
    }
   ],
   "source": [
    "# initiate an empty list to store dataframes from each episode\n",
    "scripts = []\n",
    "for url in urls:\n",
    "    r = requests.get(url)\n",
    "    html_doc = r.text\n",
    "    soup = BeautifulSoup(html_doc)\n",
    "    \n",
    "    episode_number, episode_title = get_episode(soup)\n",
    "    season = get_season(soup)\n",
    "    release_date = get_release_date(soup)\n",
    "    conversations = get_conversations(soup)\n",
    "    \n",
    "    df_scripts = create_dataframe(episode_number = episode_number, \n",
    "                                  episode_title = episode_title,\n",
    "                                  season = season,\n",
    "                                  release_date = release_date,\n",
    "                                  conversations = conversations)\n",
    "    \n",
    "    scripts.append(df_scripts)\n",
    "    print('Script from: ' + url + ' added')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26099 entries, 0 to 292\n",
      "Data columns (total 6 columns):\n",
      "Release Date     26099 non-null object\n",
      "Season           26099 non-null object\n",
      "Episode          26099 non-null object\n",
      "Episode Title    26099 non-null object\n",
      "Name             26099 non-null object\n",
      "Sentence         26099 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "script_dataframe = pd.concat(scripts)\n",
    "script_dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have collected all scripts for the whole season of Game of Thrones in a single dataframe. However, we still keep in mind that these data are not completely clean yet. That is why what we are going to do next is doing the `Post Scrapping Data Cleansing` to make sure the dataset is safe to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Scrapping Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26099 entries, 0 to 292\n",
      "Data columns (total 6 columns):\n",
      "Release Date     26099 non-null object\n",
      "Season           26099 non-null object\n",
      "Episode          26099 non-null object\n",
      "Episode Title    26099 non-null object\n",
      "Name             26099 non-null object\n",
      "Sentence         26099 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "script_dataframe = script_dataframe.dropna()\n",
    "script_dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have encountered some `Name` and `Sentence` that contain some bracketed strings in previous sections. This can describe about what the person is thinking or refers to the audience of the person talking. We don't need these to ruin our data, therefore we need to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>EPISODE</td>\n",
       "      <td>1 - WINTER IS COMING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>WAYMAR ROYCE</td>\n",
       "      <td>What d’you expect? They’re savages. One lot s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>WILL</td>\n",
       "      <td>I’ve never seen wildlings do a thing like thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Release Date    Season    Episode     Episode Title          Name  \\\n",
       "0   2011-04-17  Season 1  Episode 1  Winter is Coming       EPISODE   \n",
       "1   2011-04-17  Season 1  Episode 1  Winter is Coming  WAYMAR ROYCE   \n",
       "2   2011-04-17  Season 1  Episode 1  Winter is Coming          WILL   \n",
       "\n",
       "                                            Sentence  \n",
       "0                               1 - WINTER IS COMING  \n",
       "1   What d’you expect? They’re savages. One lot s...  \n",
       "2   I’ve never seen wildlings do a thing like thi...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def remove_bracketed(text):\n",
    "    regex = '\\([^)]*\\)'\n",
    "    text = re.sub(regex, '', text).replace('  ',' ')\n",
    "    return text\n",
    "\n",
    "script_dataframe['Name'] = script_dataframe['Name'].apply(remove_bracketed)\n",
    "script_dataframe['Sentence'] = script_dataframe['Sentence'].apply(remove_bracketed)\n",
    "\n",
    "script_dataframe.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have already eliminated null values on our dataframe and also eliminated bracketed text from column `Name` and `Sentence` on our dataframe.\n",
    "\n",
    "For further cleansing, we need to make values of our `Name` column homogenous. First thing we need to do to achieve this is making the `Name` column in lowercase text format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>episode</td>\n",
       "      <td>1 - WINTER IS COMING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>What d’you expect? They’re savages. One lot s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>I’ve never seen wildlings do a thing like thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Release Date    Season    Episode     Episode Title          Name  \\\n",
       "0   2011-04-17  Season 1  Episode 1  Winter is Coming       episode   \n",
       "1   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "2   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "\n",
       "                                            Sentence  \n",
       "0                               1 - WINTER IS COMING  \n",
       "1   What d’you expect? They’re savages. One lot s...  \n",
       "2   I’ve never seen wildlings do a thing like thi...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_dataframe['Name'] = script_dataframe['Name'].apply(lambda x: str(x).lower())\n",
    "script_dataframe.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making all names in lowercase format, we need to remove all non-aphabetical character in `Name` column. We can make a simple function to do regex substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_non_alphabetic(text):\n",
    "    regex = '[^A-Za-z\\s]'\n",
    "    text = re.sub(regex, '', text).replace('  ',' ')\n",
    "    text = text if text[-1] != ' ' else text[:-1]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>episode</td>\n",
       "      <td>1 - WINTER IS COMING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>What d’you expect? They’re savages. One lot s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>I’ve never seen wildlings do a thing like thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Release Date    Season    Episode     Episode Title          Name  \\\n",
       "0   2011-04-17  Season 1  Episode 1  Winter is Coming       episode   \n",
       "1   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "2   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "\n",
       "                                            Sentence  \n",
       "0                               1 - WINTER IS COMING  \n",
       "1   What d’you expect? They’re savages. One lot s...  \n",
       "2   I’ve never seen wildlings do a thing like thi...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_dataframe['Name'] = script_dataframe['Name'].apply(remove_non_alphabetic)\n",
    "script_dataframe.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all names in similar format, in lowercase and only consist of alphabetic characters.The first thing we need to do now is removing the naration text from our dataframe. As we previously known, some of the background conditions which categorized as narations are written in the same format as conversation. Some examples for this case are `EPISODE` and `CUT TO`.\n",
    "\n",
    "Easiest way to do this is by extracting the first word of each names and put them into a new column. This column will later be used to filter the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>First Token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>episode</td>\n",
       "      <td>1 - WINTER IS COMING</td>\n",
       "      <td>episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>What d’you expect? They’re savages. One lot s...</td>\n",
       "      <td>waymar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>I’ve never seen wildlings do a thing like thi...</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Release Date    Season    Episode     Episode Title          Name  \\\n",
       "0   2011-04-17  Season 1  Episode 1  Winter is Coming       episode   \n",
       "1   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "2   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "\n",
       "                                            Sentence First Token  \n",
       "0                               1 - WINTER IS COMING     episode  \n",
       "1   What d’you expect? They’re savages. One lot s...      waymar  \n",
       "2   I’ve never seen wildlings do a thing like thi...        will  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_dataframe['First Token'] = script_dataframe['Name'].apply(lambda x: str(x).split(' ')[0])\n",
    "script_dataframe.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue, we will now filter the background conditions from our dataframe. These entries will have `First Token` such as `episode`, `cut`, `int`, and `ext`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>First Token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>What d’you expect? They’re savages. One lot s...</td>\n",
       "      <td>waymar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>I’ve never seen wildlings do a thing like thi...</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>How close did you get?</td>\n",
       "      <td>waymar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Release Date    Season    Episode     Episode Title          Name  \\\n",
       "1   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "2   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "3   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "\n",
       "                                            Sentence First Token  \n",
       "1   What d’you expect? They’re savages. One lot s...      waymar  \n",
       "2   I’ve never seen wildlings do a thing like thi...        will  \n",
       "3                             How close did you get?      waymar  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_dataframe = script_dataframe[(script_dataframe['First Token'] != 'cut') &\n",
    "                                    (script_dataframe['First Token'] != 'int') &\n",
    "                                    (script_dataframe['First Token'] != 'ext') &\n",
    "                                    (script_dataframe['First Token'] != 'episode')]\n",
    "script_dataframe.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have now filtered all of the backgoud conditions from our dataframe. Let's focus on column `Name` again.\n",
    "\n",
    "We should check if this column only has normal name as its entries. There are many cases that can be considered as anomaly in person's name, such as name length. For now we will see are there any anomaly length on our `Name` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count       24354.000000\n",
      "mean            6.734458\n",
      "std             3.771149\n",
      "min             2.000000\n",
      "50%             6.000000\n",
      "80%             8.000000\n",
      "90%            12.000000\n",
      "95%            13.000000\n",
      "99%            17.000000\n",
      "99.9%          21.000000\n",
      "99.99%         23.000000\n",
      "99.999%       251.158650\n",
      "99.9999%      315.815865\n",
      "max           323.000000\n",
      "Name: Name Length, dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24354 entries, 1 to 290\n",
      "Data columns (total 8 columns):\n",
      "Release Date     24354 non-null object\n",
      "Season           24354 non-null object\n",
      "Episode          24354 non-null object\n",
      "Episode Title    24354 non-null object\n",
      "Name             24354 non-null object\n",
      "Sentence         24354 non-null object\n",
      "First Token      24354 non-null object\n",
      "Name Length      24354 non-null int64\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 1.7+ MB\n",
      "None\n",
      "28      1\n",
      "323     1\n",
      "20      3\n",
      "22      3\n",
      "23     12\n",
      "Name: Name Length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "script_dataframe['Name Length'] = script_dataframe['Name'].apply(lambda x: len(str(x)))\n",
    "print(script_dataframe['Name Length'].describe(percentiles=[.8,.9,.95,.99,.999,.9999,.99999,.999999]))\n",
    "print(script_dataframe.info())\n",
    "print(script_dataframe['Name Length'].value_counts().sort_values().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on information above, we know that most of our value in column `Name` only have length no longer than 28 characters. In fact, as an outlier we have one name that consists of more than 300 characters.\n",
    "\n",
    "Once again, just like null values on data, there are also many ways to handle outlier values on data. But for this case we will just eliminate the outlier because it only has small number, just one entry to be precise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24353 entries, 1 to 290\n",
      "Data columns (total 8 columns):\n",
      "Release Date     24353 non-null object\n",
      "Season           24353 non-null object\n",
      "Episode          24353 non-null object\n",
      "Episode Title    24353 non-null object\n",
      "Name             24353 non-null object\n",
      "Sentence         24353 non-null object\n",
      "First Token      24353 non-null object\n",
      "Name Length      24353 non-null int64\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "script_dataframe = script_dataframe[script_dataframe['Name Length'] <= 28]\n",
    "script_dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Homogenization\n",
    "As the next step, we previously know that our `Name` column may have different values for a same person. This can happen because of aliases, family names, nicknames, and others. However, it will take a lot of effort if we make all of our `Name` value homogen. Instead of doing that, we will just make homogen name of characters that matter the most in the data. Now let's see who are those characters that matter the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     638.000000\n",
       "mean       38.170846\n",
       "std       118.213483\n",
       "min         1.000000\n",
       "50%         5.000000\n",
       "80%        32.000000\n",
       "90%        83.900000\n",
       "95%       182.750000\n",
       "99%       637.950000\n",
       "99.9%    1161.402000\n",
       "max      1578.000000\n",
       "Name: Sentence, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appearance_counts = script_dataframe.groupby(['Name'])['Sentence'].count().reset_index()\n",
    "appearance_counts.Sentence.describe(percentiles=[.8,.9,.95,.99,.999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on information above, we figured that only 10% of the characters have more than 80 different sentences. These characters will we be focused on and made homogen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_sentence_characters = appearance_counts[appearance_counts['Sentence'] > 80].sort_values(by=['Sentence'], ascending=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a peek on the dataset, we will see that characters on this dataset still consist of some universal aliases like `man` and `soldier` which are not owned by a single character, instead used by many different characters. These aliases should be removed from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_sentence_characters = most_sentence_characters[(most_sentence_characters['Name'] != 'man') &\n",
    "                                                    (most_sentence_characters['Name'] != 'soldier')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we already removed all of the universal aliases from our character dataframes. Let's take a look of its unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 63\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['tyrion', 'jon', 'cersei', 'daenerys', 'jaime', 'sansa', 'arya',\n",
       "       'davos', 'theon', 'sam', 'bronn', 'varys', 'brienne', 'bran',\n",
       "       'tywin', 'jorah', 'stannis', 'margaery', 'ramsay', 'melisandre',\n",
       "       'robb', 'eddard stark', 'jon snow', 'shae', 'gendry',\n",
       "       'littlefinger', 'joffrey', 'tormund', 'gilly', 'tyrion lannister',\n",
       "       'missandei', 'catelyn', 'ygritte', 'olenna', 'daario', 'podrick',\n",
       "       'yara', 'the hound', 'osha', 'oberyn', 'baelish', 'sandor',\n",
       "       'tommen', 'jaqen', 'grey worm', 'qyburn', 'talisa',\n",
       "       'petyr baelish', 'meera', 'catelyn stark', 'samwell', 'thoros',\n",
       "       'daenerys targaryen', 'robert baratheon', 'arya stark', 'shireen',\n",
       "       'high sparrow', 'beric', 'euron', 'hound', 'sansa stark', 'grenn',\n",
       "       'jorah mormont'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_names = most_sentence_characters['Name'].unique()\n",
    "print('total: ' + str(len(char_names)))\n",
    "char_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 63 characters with more than 80 sentences (from now on we will address this as `important characters`) are left on our character dataframe. It takes not a big effort for us to manually homogenize the names on this list. Also, notice that some of the characters on this list have other name or alias in the series. We are going to make a mapping for these aliases too.\n",
    "\n",
    "For now, we will make a new dataframe containing unique name and alias from these characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base Name</th>\n",
       "      <th>Alias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arya stark</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beric</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bran stark</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brienne</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bronn</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Base Name Alias\n",
       "0  arya stark  None\n",
       "1       beric  None\n",
       "2  bran stark  None\n",
       "3     brienne  None\n",
       "4       bronn  None"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_names = ['tyrion lannister', 'jon snow', 'jaime lannister', 'sansa stark', 'arya stark', 'davos',\n",
    "              'theon greyjoy', 'bronn', 'varys', 'brienne', 'bran stark', 'tywin lannister', 'jorah mormont', 'stannis baratheon',\n",
    "              'margaery tyrell', 'ramsay bolton', 'melisandre', 'robb stark', 'jon snow', 'shae', 'gendry baratheon',\n",
    "              'tormund', 'gilly', 'tyrion lannister', 'missandei', 'catelyn stark', 'ygritte', 'olenna tyrell', 'daario',\n",
    "              'podrick', 'yara greyjoy', 'osha', 'oberyn martell', 'jaqen hghar','grey worm', 'qyburn', 'talisa', 'meera', 'catelyn stark',\n",
    "              'thoros','robert baratheon', 'arya stark', 'shireen', 'sparrow', 'beric', 'euron greyjoy','sansa stark', 'grenn', 'jorah mormont']\n",
    "\n",
    "alias_mapper = ['sandor clegane','petyr baelish','petyr baelish','sam tarly','eddard stark','cersei lannister','joffrey lannister',\n",
    "                'tommen lannister','daenerys targaryen','daenerys targaryen']\n",
    "\n",
    "alias = ['hound','littlefinger','baelish','samwell tarly','ned stark','cersei baratheon','joffrey baratheon',\n",
    "         'tommen baratheon','daenerys stormborn','dany']\n",
    "\n",
    "char_names = sorted(list(pd.Series(char_names).unique()))\n",
    "char_alias = [None for i in range(0, len(char_names))]\n",
    "char_names.extend(alias_mapper)\n",
    "char_alias.extend(alias)\n",
    "name_dictionary = pd.DataFrame({\n",
    "    \"Base Name\": char_names,\n",
    "    \"Alias\": char_alias\n",
    "})\n",
    "\n",
    "name_dictionary = name_dictionary[['Base Name','Alias']]\n",
    "name_dictionary = name_dictionary.sort_values(by=['Base Name'])\n",
    "name_dictionary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing the name dictionary for important characters, the next thing we do is mapping these name to our main dataframe. We will first make a mapper dataframe to be used later for mapping purpose. To do this we need to make a copy of our main dataframe.\n",
    "\n",
    "But before we make a copy, there are some cases that need to be highlighted. Some of the character aliases contain word like `high` and `the`, for example `high sparrow` and `the hound`. Keeping these words will get us into trouble when scoring the string similarity later because these words will increase the scores two different names that have prefix of these words. Therefore, we need to remove these words from our character names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_words(x):\n",
    "    new_name = x.replace('the ','')\n",
    "    new_name = new_name.replace('high ', '')\n",
    "    return new_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dataframe['Name'] = script_dataframe['Name'].apply(clean_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start making the mapper for our important characters starting with making a copy of our main dataframe as a new dataframe object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_for_mapper = script_dataframe.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of creating this mapper is generating a cartesian product of our new dataframe and our important characters dataframe. The easiest way to do this is by creating a column with similar name and values for both dataframe. This column will be used for merging in which we will use this column as a key for doing dataframe left outer merge. We add column `Cartesian Key` with value of `0` for both data frame, and then we do outer merge on those dataframes using the column `Cartesian Key`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1290709 entries, 0 to 1290708\n",
      "Data columns (total 11 columns):\n",
      "Release Date     1290709 non-null object\n",
      "Season           1290709 non-null object\n",
      "Episode          1290709 non-null object\n",
      "Episode Title    1290709 non-null object\n",
      "Name             1290709 non-null object\n",
      "Sentence         1290709 non-null object\n",
      "First Token      1290709 non-null object\n",
      "Name Length      1290709 non-null int64\n",
      "Cartesian Key    1290709 non-null int64\n",
      "Base Name        1290709 non-null object\n",
      "Alias            243530 non-null object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 118.2+ MB\n"
     ]
    }
   ],
   "source": [
    "script_for_mapper['Cartesian Key'] = 0\n",
    "name_dictionary['Cartesian Key'] = 0\n",
    "script_for_mapper = script_for_mapper.merge(name_dictionary, on=['Cartesian Key'], how='outer')\n",
    "script_for_mapper.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there is massive increase on number of rows of our dataframe. This is happened because of cartesian product basically mapping every rows in first dataframe to every rows in second dataframe. It increases total row by multiplying number of rows of first dataframe by number of rows of second dataframe.\n",
    "\n",
    "In order to create a proper mapper, we need to make sure that each name of our dataframe is the really the name of our important characters. In this process we will also tackle case of typo writing on our dataframe. To do this we will get similarity score between our character names and the important characters dataset, either the name or the alias.\n",
    "\n",
    "This algorithm below will do the scoring process. As for the string similarity, after some researches I found that the most suitable algorithm for this is the `Jaro Winkler` algorithm. I will use package from `jellyfish` that contains `Jaro Winkler` algorithm. You can read more about `Jaro Winkler` algorithm here https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance, and the `jellyfish` documentation here https://jellyfish.readthedocs.io/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jellyfish\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/80/bcacc7affb47be7279d7d35225e1a932416ed051b315a7f9df20acf04cbe/jellyfish-0.7.2.tar.gz (133kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 5.0MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: jellyfish\n",
      "  Building wheel for jellyfish (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jellyfish: filename=jellyfish-0.7.2-cp36-cp36m-linux_x86_64.whl size=81345 sha256=4cf18c0b00f76d926094c15b0ad3c17fb39dcd82bc00d3cab1d7f82b3795188c\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/e8/fe/99/d8fa8f2ef7b82a625b0b77a84d319b0b50693659823c4effb4\n",
      "Successfully built jellyfish\n",
      "Installing collected packages: jellyfish\n",
      "Successfully installed jellyfish-0.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install jellyfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jellyfish import jaro_winkler\n",
    "\n",
    "def get_similarity(row):\n",
    "    current_name = row['Name']\n",
    "    base_name = row['Base Name']\n",
    "    alias = row['Alias']\n",
    "    \n",
    "    score_base_name = 0\n",
    "    score_alias = 0\n",
    "    \n",
    "    if current_name == base_name:\n",
    "        score_base_name = 1\n",
    "    else:\n",
    "        listed_current_name = current_name.split(' ')\n",
    "        listed_base_name = base_name.split(' ')\n",
    "        \n",
    "        if len(listed_current_name) > 1 and len(listed_base_name) > 1:\n",
    "            family_name_similarity = jaro_winkler(listed_current_name[1], listed_base_name[1])\n",
    "            if family_name_similarity > .9:\n",
    "                score_base_name = jaro_winkler(listed_current_name[0], listed_base_name[0])\n",
    "            else:\n",
    "                score_base_name = jaro_winkler(current_name, base_name)\n",
    "        elif len(listed_base_name) > 1:\n",
    "            score_base_name = jaro_winkler(current_name, listed_base_name[0])\n",
    "        else:\n",
    "            score_base_name = jaro_winkler(current_name, base_name)\n",
    "        \n",
    "        if alias != None:\n",
    "            listed_alias = alias.split(' ')\n",
    "            if len(listed_current_name) > 1 and len(listed_alias) > 1:\n",
    "                family_name_similarity = jaro_winkler(listed_current_name[1], listed_alias[1])\n",
    "                if family_name_similarity > .9:\n",
    "                    score_base_name = jaro_winkler(listed_current_name[0], listed_alias[0])\n",
    "                else:\n",
    "                    score_base_name = jaro_winkler(current_name, alias)\n",
    "            elif len(listed_alias) > 1:\n",
    "                score_base_name = jaro_winkler(current_name, listed_alias[0])\n",
    "            else:\n",
    "                score_base_name = jaro_winkler(current_name, alias)\n",
    "    \n",
    "    return score_base_name if score_base_name > score_alias else score_alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_for_mapper['Name Similarity'] = script_for_mapper.apply(get_similarity, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some data exploration I found that minimum score for the name similarity that can be accepted as a same character is `0.89`. Therefore, we will make a new name column named `Homogenized Name` and fill them with condition if the similarity score is greater than `0.89` use name from the important character dataset, which in this dataframe stored as `Base Name` column, and for rows with similarity score les than `0.89` use `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_homogenized_name(x):\n",
    "    similarity = x['Name Similarity']\n",
    "    name = x['Name']\n",
    "    base_name = x['Base Name']\n",
    "    \n",
    "    if similarity > .89:\n",
    "        return base_name\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>First Token</th>\n",
       "      <th>Name Length</th>\n",
       "      <th>Cartesian Key</th>\n",
       "      <th>Base Name</th>\n",
       "      <th>Alias</th>\n",
       "      <th>Name Similarity</th>\n",
       "      <th>Homogenized Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>What d’you expect? They’re savages. One lot s...</td>\n",
       "      <td>waymar</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>arya stark</td>\n",
       "      <td>None</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>What d’you expect? They’re savages. One lot s...</td>\n",
       "      <td>waymar</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>beric</td>\n",
       "      <td>None</td>\n",
       "      <td>0.427778</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>What d’you expect? They’re savages. One lot s...</td>\n",
       "      <td>waymar</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>bran stark</td>\n",
       "      <td>None</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>What d’you expect? They’re savages. One lot s...</td>\n",
       "      <td>waymar</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>brienne</td>\n",
       "      <td>None</td>\n",
       "      <td>0.484127</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>What d’you expect? They’re savages. One lot s...</td>\n",
       "      <td>waymar</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>bronn</td>\n",
       "      <td>None</td>\n",
       "      <td>0.427778</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Release Date    Season    Episode     Episode Title          Name  \\\n",
       "0   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "1   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "2   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "3   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "4   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "\n",
       "                                            Sentence First Token  Name Length  \\\n",
       "0   What d’you expect? They’re savages. One lot s...      waymar           12   \n",
       "1   What d’you expect? They’re savages. One lot s...      waymar           12   \n",
       "2   What d’you expect? They’re savages. One lot s...      waymar           12   \n",
       "3   What d’you expect? They’re savages. One lot s...      waymar           12   \n",
       "4   What d’you expect? They’re savages. One lot s...      waymar           12   \n",
       "\n",
       "   Cartesian Key   Base Name Alias  Name Similarity Homogenized Name  \n",
       "0              0  arya stark  None         0.644444             None  \n",
       "1              0       beric  None         0.427778             None  \n",
       "2              0  bran stark  None         0.572222             None  \n",
       "3              0     brienne  None         0.484127             None  \n",
       "4              0       bronn  None         0.427778             None  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_for_mapper['Homogenized Name'] = script_for_mapper.apply(get_homogenized_name, axis=1)\n",
    "script_for_mapper.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, we should have our important characters with both of their `Name` and `Homogenized Name` filled with non null object. Next we will do is extracting the `Name` and `Homogenized Name` columns and dropping the `None` values so that the dataframe only contains name of our important characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Homogenized Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>jon</td>\n",
       "      <td>jon snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>sansa</td>\n",
       "      <td>sansa stark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>ned</td>\n",
       "      <td>eddard stark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>robb</td>\n",
       "      <td>robb stark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>catelyn</td>\n",
       "      <td>catelyn stark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name Homogenized Name\n",
       "815       jon         jon snow\n",
       "992     sansa      sansa stark\n",
       "1071      ned     eddard stark\n",
       "1200     robb       robb stark\n",
       "1383  catelyn    catelyn stark"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_for_mapper = script_for_mapper[['Name','Homogenized Name']].dropna().drop_duplicates()\n",
    "script_for_mapper.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, there is a special case on this mapper. A character named `Robett Glover` is mapped as `Robert Baratheon` on our mapper. This is happened because on the script from `genius.com`, they wrote the name `robett` without the family name. If you read our algorithm for scoring the string similarity, after comparing name of `robett` and `robert` the algorithm will give a high similarity score as result. For this case, I will manually delete the row from our mapper since it is the fastest way for cleaning the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_for_mapper = script_for_mapper.drop(1031097)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a clean mapper for our important characters, we can finally map the name in our main dataframe to our important characters mapper dataframe. We can do the mapping by doing a simple pandas left merge on column `Name` of each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>First Token</th>\n",
       "      <th>Name Length</th>\n",
       "      <th>Homogenized Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>What d’you expect? They’re savages. One lot s...</td>\n",
       "      <td>waymar</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>I’ve never seen wildlings do a thing like thi...</td>\n",
       "      <td>will</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>How close did you get?</td>\n",
       "      <td>waymar</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>Close as any man would.</td>\n",
       "      <td>will</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>gared</td>\n",
       "      <td>We should head back to the wall.</td>\n",
       "      <td>gared</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Release Date    Season    Episode     Episode Title          Name  \\\n",
       "0   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "1   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "2   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "3   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "4   2011-04-17  Season 1  Episode 1  Winter is Coming         gared   \n",
       "\n",
       "                                            Sentence First Token  Name Length  \\\n",
       "0   What d’you expect? They’re savages. One lot s...      waymar           12   \n",
       "1   I’ve never seen wildlings do a thing like thi...        will            4   \n",
       "2                             How close did you get?      waymar           12   \n",
       "3                            Close as any man would.        will            4   \n",
       "4                   We should head back to the wall.       gared            5   \n",
       "\n",
       "  Homogenized Name  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_dataframe = script_dataframe.merge(script_for_mapper, on=['Name'], how='left')\n",
    "script_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have successfully mapped the name of our important characters to their name on main dataframe. We will now clean the `Name` column by filling them with available value in `Homogenized Name` column, or we can say changing the name of our important characters to their clean name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>First Token</th>\n",
       "      <th>Name Length</th>\n",
       "      <th>Homogenized Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>What d’you expect? They’re savages. One lot s...</td>\n",
       "      <td>waymar</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>I’ve never seen wildlings do a thing like thi...</td>\n",
       "      <td>will</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>How close did you get?</td>\n",
       "      <td>waymar</td>\n",
       "      <td>12</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>Close as any man would.</td>\n",
       "      <td>will</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>gared</td>\n",
       "      <td>We should head back to the wall.</td>\n",
       "      <td>gared</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Release Date    Season    Episode     Episode Title          Name  \\\n",
       "0   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "1   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "2   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "3   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "4   2011-04-17  Season 1  Episode 1  Winter is Coming         gared   \n",
       "\n",
       "                                            Sentence First Token  Name Length  \\\n",
       "0   What d’you expect? They’re savages. One lot s...      waymar           12   \n",
       "1   I’ve never seen wildlings do a thing like thi...        will            4   \n",
       "2                             How close did you get?      waymar           12   \n",
       "3                            Close as any man would.        will            4   \n",
       "4                   We should head back to the wall.       gared            5   \n",
       "\n",
       "  Homogenized Name  \n",
       "0                   \n",
       "1                   \n",
       "2                   \n",
       "3                   \n",
       "4                   "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_dataframe['Homogenized Name'] = script_dataframe['Homogenized Name'].fillna('')\n",
    "script_dataframe['Name'] = script_dataframe[['Name','Homogenized Name']].apply(lambda x: x[1] if x[1] != '' else x[0], axis=1)\n",
    "script_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we managed to map and homogenize the name of our important characters. Let's restore our main dataframe to its orginal format and remove the duplicated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>What d’you expect? They’re savages. One lot s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>I’ve never seen wildlings do a thing like thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>How close did you get?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>Close as any man would.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>gared</td>\n",
       "      <td>We should head back to the wall.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Release Date    Season    Episode     Episode Title          Name  \\\n",
       "0   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "1   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "2   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "3   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "4   2011-04-17  Season 1  Episode 1  Winter is Coming         gared   \n",
       "\n",
       "                                            Sentence  \n",
       "0   What d’you expect? They’re savages. One lot s...  \n",
       "1   I’ve never seen wildlings do a thing like thi...  \n",
       "2                             How close did you get?  \n",
       "3                            Close as any man would.  \n",
       "4                   We should head back to the wall.  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_dataframe = script_dataframe[['Release Date','Season','Episode','Episode Title','Name','Sentence']].drop_duplicates()\n",
    "script_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Cleansing\n",
    "Case that most likely occured on column `Sentence` is not as much as in `Name` column. One of the reason is because we already clean some of them on `Name` cleansing process.\n",
    "\n",
    "However there are still cases that make our the `Sentence` column still contains dirty data. First case is the sentence is not properly started meaning that first character on the sentence is a non-aphanumeric character. This can happen because of our previous cleansing in which we remove the bracketed text on our `Name` and `Sentence` columns. Next case is the sentence written in differen format than most of them, or to be specific some sentences are written inside quote `''` or double quote `\"\"`, while others are not. The last case is sentences that contain empty string which might also happen because of removing of the bracketed texts.\n",
    "\n",
    "The function below contains algorithm that is going to handle the non-proper form sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_sentence(text):\n",
    "    \n",
    "    text_list = text.split(' ')\n",
    "    \n",
    "    if len(text_list) > 1:\n",
    "        text = ''.join(' ' + word for word in text_list if word != '')[1:].replace('    ',' ').replace('   ',' ').replace('  ',' ')\n",
    "        if len(text) > 1:\n",
    "            text = text[:-1] if text[-1] == ' ' else text\n",
    "            if text[0] == '\"' and text[-1] == '\"':\n",
    "                text = text[1:-1]\n",
    "            if text[0] == '\\'' and text[-1] == '\\'':\n",
    "                text = text[1:-1]\n",
    "\n",
    "        regex = '^[^A-Za-z0-9]*'\n",
    "        text = re.sub(regex, '', text).replace('  ',' ')\n",
    "        if len(text) > 0:\n",
    "            text = text if text[-1] != ' ' else text[:-1]\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Clean Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>What d’you expect? They’re savages. One lot s...</td>\n",
       "      <td>What d’you expect? They’re savages. One lot st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>I’ve never seen wildlings do a thing like thi...</td>\n",
       "      <td>I’ve never seen wildlings do a thing like this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>How close did you get?</td>\n",
       "      <td>How close did you get?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Release Date    Season    Episode     Episode Title          Name  \\\n",
       "0   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "1   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "2   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "\n",
       "                                            Sentence  \\\n",
       "0   What d’you expect? They’re savages. One lot s...   \n",
       "1   I’ve never seen wildlings do a thing like thi...   \n",
       "2                             How close did you get?   \n",
       "\n",
       "                                      Clean Sentence  \n",
       "0  What d’you expect? They’re savages. One lot st...  \n",
       "1  I’ve never seen wildlings do a thing like this...  \n",
       "2                             How close did you get?  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_dataframe['Clean Sentence'] = script_dataframe['Sentence'].apply(clean_sentence)\n",
    "script_dataframe.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the `Sentence` column values should all be in the same format. The last case that needed to be handled is the empty string. We can easily handle this by making a new column that contains value of the lenght of each `Sentence` value in our main dataframe. And then use the column to filter empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Clean Sentence</th>\n",
       "      <th>Length Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>What d’you expect? They’re savages. One lot s...</td>\n",
       "      <td>What d’you expect? They’re savages. One lot st...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>I’ve never seen wildlings do a thing like thi...</td>\n",
       "      <td>I’ve never seen wildlings do a thing like this...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>How close did you get?</td>\n",
       "      <td>How close did you get?</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Release Date    Season    Episode     Episode Title          Name  \\\n",
       "0   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "1   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "2   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "\n",
       "                                            Sentence  \\\n",
       "0   What d’you expect? They’re savages. One lot s...   \n",
       "1   I’ve never seen wildlings do a thing like thi...   \n",
       "2                             How close did you get?   \n",
       "\n",
       "                                      Clean Sentence  Length Sentence  \n",
       "0  What d’you expect? They’re savages. One lot st...              136  \n",
       "1  I’ve never seen wildlings do a thing like this...              103  \n",
       "2                             How close did you get?               22  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_dataframe['Length Sentence'] = script_dataframe['Clean Sentence'].apply(len)\n",
    "script_dataframe = script_dataframe[script_dataframe['Length Sentence'] > 1]\n",
    "script_dataframe.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already have a clean sentence and also removed all empty strings on our dataframe. Now we should replace values on `Sentence` column using the values on `Clean Sentence` column and then restore our dataframe to its original structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>What d’you expect? They’re savages. One lot st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>I’ve never seen wildlings do a thing like this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>How close did you get?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>Close as any man would.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>gared</td>\n",
       "      <td>We should head back to the wall.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Release Date    Season    Episode     Episode Title          Name  \\\n",
       "0   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "1   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "2   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "3   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "4   2011-04-17  Season 1  Episode 1  Winter is Coming         gared   \n",
       "\n",
       "                                            Sentence  \n",
       "0  What d’you expect? They’re savages. One lot st...  \n",
       "1  I’ve never seen wildlings do a thing like this...  \n",
       "2                             How close did you get?  \n",
       "3                            Close as any man would.  \n",
       "4                   We should head back to the wall.  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_dataframe['Sentence'] = script_dataframe['Clean Sentence']\n",
    "script_dataframe = script_dataframe[['Release Date','Season','Episode','Episode Title','Name','Sentence']].drop_duplicates()\n",
    "script_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final touch, it might be hard to notice but quote symbol in `Sentence` column is using `’` instead of `'`. A simple regex replace can fix this problem. While we are doing this, we can as well replace the `d’` word that can easily be seen on the first row. This is actually a simple alternative for word `do`. Again, we will use regex replace to fix them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Episode Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>What do you expect? They're savages. One lot s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>I've never seen wildlings do a thing like this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>How close did you get?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>will</td>\n",
       "      <td>Close as any man would.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-04-17</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>Episode 1</td>\n",
       "      <td>Winter is Coming</td>\n",
       "      <td>gared</td>\n",
       "      <td>We should head back to the wall.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Release Date    Season    Episode     Episode Title          Name  \\\n",
       "0   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "1   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "2   2011-04-17  Season 1  Episode 1  Winter is Coming  waymar royce   \n",
       "3   2011-04-17  Season 1  Episode 1  Winter is Coming          will   \n",
       "4   2011-04-17  Season 1  Episode 1  Winter is Coming         gared   \n",
       "\n",
       "                                            Sentence  \n",
       "0  What do you expect? They're savages. One lot s...  \n",
       "1  I've never seen wildlings do a thing like this...  \n",
       "2                             How close did you get?  \n",
       "3                            Close as any man would.  \n",
       "4                   We should head back to the wall.  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_dataframe['Sentence'] = script_dataframe['Sentence'].apply(lambda x: str(x).replace('’', '\\''))\n",
    "script_dataframe['Sentence'] = script_dataframe['Sentence'].apply(lambda x: str(x).replace('d\\'', 'do '))\n",
    "script_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 23911 entries, 0 to 24353\n",
      "Data columns (total 6 columns):\n",
      "Release Date     23911 non-null object\n",
      "Season           23911 non-null object\n",
      "Episode          23911 non-null object\n",
      "Episode Title    23911 non-null object\n",
      "Name             23911 non-null object\n",
      "Sentence         23911 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "script_dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, our process in scrapping and cleansing the dataset for `Game of Thrones` has finished. The last thing to do is export the dataframe to an external file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dataframe.to_csv('Game_of_Thrones_Script.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Scrapping web to extract the data scattered around them may take a lot of effort. We need to do bunch of manual inspect element just to get the exact position of data or information that we want to collect from all over the html parts. BeautifulSoup functionality is good, but for case like this we need to combine this package with manual inspect element to produce the desired result faster. Some of you might have different and even a better solution on extracting data from online sources, and that is a great thing. As for me, I am still learning and experimenting different methodologies to find my best practice on doing so.\n",
    "\n",
    "As for the closing, you can use this data and mine the information provided there as you please. Also, give me feedback both on this dataset and the process of getting them if you have the time. \n",
    "\n",
    "Thank you! \n",
    "\n",
    "And, Have a nice day:)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
