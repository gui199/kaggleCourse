{"cells":[{"metadata":{},"cell_type":"markdown","source":"**This notebook is an exercise in the [Computer Vision](https://www.kaggle.com/learn/computer-vision) course.  You can reference the tutorial at [this link](https://www.kaggle.com/ryanholbrook/data-augmentation).**\n\n---\n"},{"metadata":{},"cell_type":"markdown","source":"# Introduction #\n\nIn these exercises, you'll explore what effect various random transformations have on an image, consider what kind of augmentation might be appropriate on a given dataset, and then use data augmentation with the *Car or Truck* dataset to train a custom network.\n\nRun the cell below to set everything up!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setup feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.computer_vision.ex6 import *\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\nimport tensorflow_datasets as tfds\n\n# Imports\nimport os, warnings\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n\n# Reproducability\ndef set_seed(seed=31415):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\nset_seed()\n\n# Set Matplotlib defaults\nplt.rc('figure', autolayout=True)\nplt.rc('axes', labelweight='bold', labelsize='large',\n       titleweight='bold', titlesize=18, titlepad=10)\nplt.rc('image', cmap='magma')\nwarnings.filterwarnings(\"ignore\") # to clean up output cells\n\n\n# Load training and validation sets\nds_train_ = image_dataset_from_directory(\n    '../input/car-or-truck/train',\n    labels='inferred',\n    label_mode='binary',\n    image_size=[128, 128],\n    interpolation='nearest',\n    batch_size=64,\n    shuffle=True,\n)\nds_valid_ = image_dataset_from_directory(\n    '../input/car-or-truck/valid',\n    labels='inferred',\n    label_mode='binary',\n    image_size=[128, 128],\n    interpolation='nearest',\n    batch_size=64,\n    shuffle=False,\n)\n\n# Data Pipeline\ndef convert_to_float(image, label):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image, label\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nds_train = (\n    ds_train_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\nds_valid = (\n    ds_valid_\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# (Optional) Explore Augmentation #\n\nUncomment a transformation and run the cell to see what it does. You can experiment with the parameter values too, if you like. (The `factor` parameters should be greater than 0 and, generally, less than 1.) Run the cell again if you'd like to get a new random image."},{"metadata":{"lines_to_next_cell":0,"trusted":true},"cell_type":"code","source":"# all of the \"factor\" parameters indicate a percent-change\naugment = keras.Sequential([\n    preprocessing.RandomContrast(factor=0.5),\n#     preprocessing.RandomFlip(mode='horizontal'), # meaning, left-to-right\n    preprocessing.RandomFlip(mode='vertical'), # meaning, top-to-bottom\n    # preprocessing.RandomWidth(factor=0.15), # horizontal stretch\n    # preprocessing.RandomRotation(factor=0.20),\n    preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n])\n\n\nex = next(iter(ds_train.unbatch().map(lambda x, y: x).batch(1)))\n\nplt.figure(figsize=(10,10))\nfor i in range(16):\n    image = augment(ex, training=True)\n    plt.subplot(4, 4, i+1)\n    plt.imshow(tf.squeeze(image))\n    plt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Do the transformations you chose seem reasonable for the *Car or Truck* dataset?"},{"metadata":{},"cell_type":"markdown","source":"In this exercise, we'll look at a few datasets and think about what kind of augmentation might be appropriate. Your reasoning might be different that what we discuss in the solution. That's okay. The point of these problems is just to think about how a transformation might interact with a classification problem -- for better or worse."},{"metadata":{},"cell_type":"markdown","source":"The [EuroSAT](https://www.kaggle.com/ryanholbrook/eurosat) dataset consists of satellite images of the Earth classified by geographic feature. Run the next cell to see some examples."},{"metadata":{"trusted":true},"cell_type":"code","source":"ds, ds_info = tfds.load('eurosat/rgb:2.0.0',\n                        with_info=True,\n                        split='train',\n                        data_dir='../input/eurosat',\n                        download=False)\nds = ds.shuffle(1024)\n\ntfds.show_examples(ds, ds_info);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1) EuroSAT #\n\nWhat kinds of transformations might be appropriate for this dataset?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# View the solution (Run this code cell to receive credit!)\nq_1.check()","execution_count":null,"outputs":[]},{"metadata":{"lines_to_next_cell":2,"trusted":false},"cell_type":"code","source":"# Lines below will give you a hint \n#q_1.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The [TensorFlow Flowers](https://www.kaggle.com/ryanholbrook/tensorflow-flowers) dataset consists of photographs of flowers of several species. Run the next cell to see some examples."},{"metadata":{"trusted":true},"cell_type":"code","source":"ds, ds_info = tfds.load('tf_flowers:3.0.1',\n                        with_info=True,\n                        split='train',\n                        data_dir='../input/tensorflow-flowers',\n                        download=False)\nds = ds.shuffle(1024)\n\ntfds.show_examples(ds, ds_info);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2) TensorFlow Flowers #\n\nWhat kinds of transformations might be appropriate for the TensorFlow Flowers dataset?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# View the solution (Run this code cell to receive credit!)\nq_2.check()","execution_count":null,"outputs":[]},{"metadata":{"lines_to_next_cell":2,"trusted":false},"cell_type":"code","source":"# Lines below will give you a hint \n#q_2.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now you'll use data augmentation with a custom convnet similar to the one you built in Exercise 5. Since data augmentation effectively increases the size of the dataset, we can increase the capacity of the model in turn without as much risk of overfitting."},{"metadata":{},"cell_type":"markdown","source":"# 3) Add Preprocessing Layers #\n\nAdd these preprocessing layers to the given model.\n\n```\npreprocessing.RandomContrast(factor=0.10),\npreprocessing.RandomFlip(mode='horizontal'),\npreprocessing.RandomRotation(factor=0.10),\n```\n"},{"metadata":{"lines_to_next_cell":2,"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\nmodel = keras.Sequential([\n    layers.InputLayer(input_shape=[128, 128, 3]),\n    \n    # Data Augmentation\n    preprocessing.RandomContrast(factor=0.10),\n    preprocessing.RandomFlip(mode='horizontal'),\n    preprocessing.RandomRotation(factor=0.10),\n\n    # Block One\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Block Two\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Block Three\n    layers.BatchNormalization(renorm=True),\n    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n    layers.MaxPool2D(),\n\n    # Head\n    layers.BatchNormalization(renorm=True),\n    layers.Flatten(),\n    layers.Dense(8, activation='relu'),\n    layers.Dense(1, activation='sigmoid'),\n])\n\n# Check your answer\nq_3.check()","execution_count":null,"outputs":[]},{"metadata":{"lines_to_next_cell":2,"trusted":false},"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q_3.hint()\n#q_3.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we'll train the model. Run the next cell to compile it with a loss and accuracy metric and fit it to the training set."},{"metadata":{"lines_to_next_cell":2,"trusted":true},"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(epsilon=0.01)\nmodel.compile(\n    optimizer=optimizer,\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)\n\nhistory = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=50,\n    verbose=2\n)\n\n# Plot learning curves\nimport pandas as pd\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4) Train Model #\n\nExamine the training curves. What there any sign of overfitting? How does the performance of this model compare to other models you've trained in this course?"},{"metadata":{"lines_to_next_cell":0,"trusted":true},"cell_type":"code","source":"# View the solution (Run this code cell to receive credit!)\nq_4.solution()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion #\n\nData augmentation is a powerful and commonly-used tool to improve model training, not only for convolutional networks, but for many other kinds of neural network models as well. Whatever your problem, the principle remains the same: you can make up for an inadequacy in your data by adding in \"fake\" data to cover it over. Experimenting with augmentations is a great way to find out just how far your data can go!"},{"metadata":{},"cell_type":"markdown","source":"# The End #\n\nThat's all for **Computer Vision** on Kaggle Learn! We hope you've enjoyed your time with us. The ideas you've learned in this course have prepared you for many other topics in deep learning; convolutional networks are used not only with images, but also with text, audio, and video. What are you interested in?\n\n- Instead of classifying images, maybe you'd like to create some new ones? **generative adversarial networks** (GANs) can learn how to do that. Check out the notebooks and discussion in the [Generative Dog Images](https://www.kaggle.com/c/generative-dog-images/) competition to learn more.\n- If you want to teach a network to learn *where* in an image something is, you might want to learn more about **image segmentation**. The [SIIM-ACR](https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/) competition challenged Kagglers to locate a lung condition called *pneumothorax* in medical scans. The convolutional U-Net model was used successfully there.\n- The [Flickr Image](https://www.kaggle.com/hsankesara/flickr-image-dataset) dataset has a number of notebooks that will show you how to make a network that can automatically generate descriptions of an image.\n- [Celeb Faces Attributes (Celeb A)](https://www.kaggle.com/jessicali9530/celeba-dataset/kernels) is a large dataset of celebrity faces with annotated descriptions. There are lots of interesting projects you could try with it.\n\nHave fun learning!"},{"metadata":{},"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum) to chat with other Learners.*"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}